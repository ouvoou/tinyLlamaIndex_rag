from src.llm_loader import load_llm
from src.embed_loader import load_embed
from src.rag_engine import build_rag_engine
def main():
    llm = load_llm("/root/autodl-tmp/LlamaIndexrag/LlamaIndex/tcm-ai-rag/tcm-ai-rag/models/Qwen/Qwen1.5-1.8B-Chat")
    embed_model = load_embed("/root/autodl-tmp/LlamaIndexrag/LlamaIndex/tcm-ai-rag/tcm-ai-rag/models/BAAI/bge-base-zh-v1.5")
    query_engine = build_rag_engine(index_path="/root/autodl-tmp/LlamaIndexrag/LlamaIndex/tcm-ai-rag/tcm-ai-rag/doc_emb", llm=llm, embed_model=embed_model)

    print("\nğŸ’¬ è¾“å…¥ä½ çš„ä¸­åŒ»é—®é¢˜ï¼Œè¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºï¼š")

    while True:
        user_input = input("ç”¨æˆ·ï¼š")
        if user_input.strip().lower() in ["exit", "quit"]:
            print("ç¨‹åºå·²é€€å‡ºã€‚")
            break
        response = query_engine.chat(user_input)
        print("LLM:", str(response))

if __name__ == '__main__':
    main()